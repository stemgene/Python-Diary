{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "File_Operation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemgene/Python-Diary/blob/master/File_Operation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZyVfnLD-UhI",
        "colab_type": "text"
      },
      "source": [
        "### Load csv from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he456QsI-ZCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/gdrive/My Drive/UR/DSC481/Project/towns.csv') as csv_file:\n",
        "  next(csv_file)\n",
        "  csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "  towns = {row[0]:[int(row[1]),float(row[2]),float(row[3])] for row in csv_reader} # load file is string type, need to transform float\n",
        "##  towns = pd.DataFrame(csv_reader4, columns=attributes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTtIzhyVN03U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stocks = pd.read_csv(\"/content/drive/My Drive/UR/DSC440_Data_Mining/Project/Data/S&P500.csv\", parse_dates=['Date']).set_index('Date')\n",
        "df = stocks.loc[:, ['Adj Close', 'Volume']].copy()\n",
        "df.rename(columns={'Adj Close': \"price\"}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaMGWQNKHSTy",
        "colab_type": "text"
      },
      "source": [
        "### Load csv to pd.Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_8BtgywHXP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cl15 = pd.read_csv('/gdrive/My Drive/UR/DSC481/Project/cluster_kmeans15.csv')[['K-means cluster']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4URNtKR1y4lM",
        "colab_type": "text"
      },
      "source": [
        "### Load csv to np.array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBpPIhY6y82R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy inmport genfromtxt\n",
        "X_train = genfromtxt('/content/drive/My Drive/UR/DSC440_Data_Mining/Project/Data/trained/X_train_622_22_16.csv', delimiter=',').reshape(622,22,16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOSdAzl8fid1",
        "colab_type": "text"
      },
      "source": [
        "### Load csv to dictionary\n",
        "\n",
        "Read in our data from a CSV file and create a dictionary of records, where the key is a unique record ID and each value is dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VACvDAHdfnd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcess(column):\n",
        "    \"\"\"\n",
        "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
        "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
        "    \"\"\"\n",
        "    try : # python 2/3 string differences\n",
        "        column = column.decode('utf8')\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    column = unidecode(column)\n",
        "    column = re.sub('  +', ' ', column)\n",
        "    column = re.sub('\\n', ' ', column)\n",
        "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
        "    # If data is missing, indicate that by setting the value to `None`\n",
        "    if not column:\n",
        "        column = None\n",
        "    return column\n",
        "\n",
        "def readData(filename):\n",
        "    data_d = {}\n",
        "    with open(filename) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
        "            row_id = int(row['Id'])\n",
        "            data_d[row_id] = dict(clean_row)\n",
        "\n",
        "    return data_d\n",
        "\n",
        "data_d = readData(input_file)\n",
        "\"\"\"\n",
        "row:\n",
        "OrderedDict([('Id', '0'), ('Source', 'CPS_Early_Childhood_Portal_scrape.csv'), ('Site name', ' Salvation Army - Temple / Salvation Army'), ('Address', '1 N Ogden Ave '), ('Zip', ''), ('Phone', '2262649')...])\n",
        "data_d:\n",
        "{0: {'Id': '0', 'Source': 'cps_early_childhood_portal_scrape.csv', 'Site name': 'salvation army - temple / salvation army', 'Address': '1 n ogden ave', 'Zip': None, 'Phone': '2262649'...}, 1: {'Id': '1', 'Source':...} \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptaK1j1c-Dfn",
        "colab_type": "text"
      },
      "source": [
        "### export dataframe to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXMjK0j9r_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#towns_df = pd.DataFrame(towns.values(), index=towns.keys(), columns=['Frequency', \"lan\", \"lon\"])\n",
        "cluster_kmeans.to_csv('cluster_kmeans15.csv')\n",
        "!cp cluster_kmeans15.csv /gdrive/My\\ Drive/UR/DSC481/Project/cluster_kmeans15.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJHgvm0jPDpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('SP500_cleaned.csv')\n",
        "!cp SP500_cleaned.csv /content/drive/My\\ Drive/UR/DSC440_Data_Mining/Project/Data/SP500_cleaned.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o9uCENVoZ9R",
        "colab_type": "text"
      },
      "source": [
        "### export numpy array to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eARXv9MXoXn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
        "!cp X_train.csv /content/drive/My\\ Drive/UR/DSC440_Data_Mining/Project/Data/trained/X_train.csv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
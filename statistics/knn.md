# KNN

在给定X后先估计Y的条件分布，然后将一个给定的观测分类到估计分布概率最大的类别中。KNN可以产生对最优贝叶斯分类器近似的分类器。

给定一个整数K和一个测试观测值 $$x_0$$ ，

1. KNN分类器从识别训练集中K个最靠近$$x_0$$的点集开始，用N0表示K个点的集合，
2. 然后对每个类别j分别用N0中的点估计一个分值作为条件概率的估计，这个值等于j： $$Pr(Y=j|X=x_0)=\frac{1}{K}\sum_{i\in N_0}I(y_i=j)$$ 
3. 最后对KNN方法运用贝叶斯规则将测试观测值$$x_0$$分到概率最大的类中

![](../.gitbook/assets/image%20%287%29.png)

上图中需要对问号❓做出预测，假设K=3，那么KNN首先先识别出最靠近问号处的三个观测值。在这个范围内有两个绿色和一个红星，结果绿色三角的估计概率就是2/3，红星的估计概率是1/3。于是KNN将问号预测为绿色族。

![](../.gitbook/assets/image%20%2820%29.png)

虚线是贝叶斯决策边界。K=1时类似过拟合，Bias比较低但Var大，当K增加到100时，模型的光滑性减弱，得到一个接近线性的决策边界，Var较低但Bias高

![](../.gitbook/assets/image%20%2823%29.png)

当1/K增加时，方法的柔性增强，training error会持续递减，但test error显示U形


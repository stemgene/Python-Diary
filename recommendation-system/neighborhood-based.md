# Neighborhood-based collaborative filtering

## 基于user的协同过滤算法collaborative filtering

当用户对一件物品有过行为（赞或顶、踩，购买等），可以找到其他也有过相同行为的其他用户，然后给他推荐那些人最近有过行为的物品。

### 基础算法：

1. 找到和目标用户兴趣相似的用户集合，即计算两个用户的兴趣相似度。令N\(u\)和N\(v\)代表u和v两个用户曾有过正反馈的物品集合。通过**Jaccard距离** $$w_{uv}=\frac{|N(u)\bigcap{N(v)}|}{|N(u)\bigcup{N(v)}|}$$或**余弦距离**$$w_{uv}=\frac{|N(u)\bigcap{N(v)}|}{\sqrt{|N(u)||N(v)|}}$$计算兴趣相似度。比如A对物品{a, b, d}有过行为，B对物品{a,c}有过行为，利用余弦相似度可以算出$$w_{AB}=\frac{|{a,b,d}\bigcap{{a,c}}|}{\sqrt{|a,b,d||a,c|}}=\frac{1}{\sqrt{6}}$$**，**同理可以算出两两用户之间的相似度。但这种方法的时间复杂度是O\(\|U\|\*\|U\|\)，很耗时，而且很多情况下结果是0。所以换个思路，先计算出 $$|N(u)\bigcap{N(v)}|\neq0$$的用户对\(u,v\)再计算其相似度。**便捷的算法：**先建立物品到用户的倒排表，对于每个用户都保存对该物品产生过行为的用户。针对物品对应的用户建立稀疏矩阵W（两个用户的位置是1，其他位置为0），W就是余弦相似度中的分子部分，然后将W/分母可以得到最终的用户兴趣相似度。
2. 找到这个集合中其他用户喜欢的，且目标用户没有听说过的物品推荐给目标客户。利用**UserCF算法**给用户推荐和他兴趣最相似的K个用户喜欢的物品。 $$p(u,i)=\sum_{v\in{S(u,K)}\bigcap{N(i)}}{w_{uv}r_{vi}}$$ 其中 $$S(u,K)$$包含和用户u兴趣最接近的K个用户，N\(i\)是对物品i有过行为的用户集合， $$w_{uv}$$是u和v的兴趣相似度， $$r_{uv}$$代表用户v对物品i的兴趣，因为使用的是但一行为的隐反馈数据，所以所有的$$r_{uv}=1$$。利用算法，选择合适的K，就可以算出用户A对物品c的兴趣 $$p(A,c)=w_{AB}+w_{AD}=0.74$$，以此类推。

![](../.gitbook/assets/image%20%2851%29.png)

### 基础算法的性能评估

用Random和MostPopular两种非个性化的推荐算法的性能作为基准。**Random**是每次随机挑选10个用户没有产生过行为的物品推荐给当前用户，**MostPoplular**是按物品的流行度给用户推荐他还没有产生行为的物品中最热门的10个物品。后者的precision和recall远高于Random，但coverage非常低，流行度较高。

![](../.gitbook/assets/image%20%2855%29.png)

针对不同的K，测量出算法的性能，对比上图，UserCF的precision和recall都有大幅提高，coverage也非常高，流行度持平。而且针对不同的K，结果会有影响。

![](../.gitbook/assets/image%20%2853%29.png)

* 精度指标Precision和recall。不和K成线性关系。而且对K也不是特别敏感，只要选在一定区域内，精度都不错。
* 流行度。K越大，流行度越好，物品越热门。因为参考人数越多，结果越趋近全局热门
* Coverage。K越大，coverage越低，因为随着流行度增加，越倾向热门物品，长尾物品的推荐就越来越少。

### 用户相似度算法改进

两个用户都对热门物品有反馈并不代表他们兴趣相似，反而如果两个用户对冷门物品有同样行为更能说明他们的兴趣相似度。因此用新的算法：

![](../.gitbook/assets/image%20%2847%29.png)

公式中通过 $$\frac{1}{log1+|N(i)|}$$ 惩罚用户u和v共同兴趣列表中热门物品对他们相似度的影响

![&#x5F53;K=80, UserCF-IIF&#x7565;&#x4F18;](../.gitbook/assets/image%20%2846%29.png)

### 此类算法的问题

用户数庞大，相似度矩阵时间空间复杂度增长为平方关系。很难对推荐结果作出解释。

## 基于item的collaborative filtering算法

ItemCF算法通过分析用户的行为记录计算物品之间的相似度，而不是利用物品自身的属性计算。即Customers who boght this item also bought...从而很好的为推荐结果提供解释。

### 基础算法

1. 计算物品之间的相似度。如果两个物品属于一个用户的兴趣列表，这两个物品可能属于有限的几个领域；如果两个物品属于很多用户的兴趣列表，他们有可能属于同一个领域，因而有很大的相似度。

   * 推荐出热门物品的物品相似度，即 $$w_{ij}$$趋近为1。喜欢物品i的用户中有多少比例的用户也喜欢物品j：$$w_{ij}=\frac{|N(i)\bigcap{N(j)}|}{|N(i)|}$$，分母\|N\(i\)\|是喜欢物品i的用户数，而分子 $$|N(i)\bigcap{N(j)}|$$是同时喜欢物品i和j的用户数。
   * 致力于挖掘长尾信息，此时物品相似度应为$$w_{ij}=\frac{|N(i)\bigcap{N(j)}|}{\sqrt{|N(i)||N(j)|}}$$，此公式惩罚了物品j的权重，因此减轻了热门物品和很多物品相似的可能性。但如果j非常热门，分子会接近\|N\(i\)\|，尽管分母已经考虑到了j的流行度，热门的j仍然会获得比较大的相似度，这就是哈利波特问题。

   首先建立用户-物品倒排表，即对每个用户建立一个包含他喜欢物品的列表，然后对于每个用户，将他物品列表中的物品两两的共现矩阵C中+1

2. 根据物品相似度和用户的历史行为给用户生成推荐列表

![](../.gitbook/assets/image%20%2863%29.png)

得到物品之间的相似度之后，itemCF通过公式计算用户u对一个物品j的兴趣, 即和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。$$p(u,j)=\sum_{v\in{S(j,K)}\bigcap{N(u)}}{w_{ji}r_{ui}}$$，N\(u\)是用户喜欢的物品的集合，S\(j,K\)是和物品j最相似的K个物品的集合， $$w_{ji}$$ 是物品j和i的相似度， $$r_{ui}$$ 是用户u对物品i的兴趣。（对于隐反馈数据机，如果用户u对物品i有过行为，即可令$$r_{ui}=1$$）

![](../.gitbook/assets/image%20%2858%29.png)

用户喜欢《C++Primer》兴趣度1.3和《编程之美》兴趣度0.9，两本书。ItemCF会为这本书分别找出和它们最相似的3本书，然后计算用户对每本书的感兴趣程度。如《算法导论》这本书和《C++Primer》相似度为0.4，和《编程之美》相似度为0.5。这本书对用户的兴趣度就是1.3\*0.4+0.9\*0.5=0.97。

### 基础算法的性能评估

![](../.gitbook/assets/image%20%2862%29.png)

* 精度指标Precision和recall。不和K成线性关系。选择合适的K对获得高精度很重要
* 流行度。不和K成线性关系，随着K增加，流行度也提高，但当K增加到一定程度，流行度不会有明显变化
* Coverage。K越大，coverage越低。

### 优化算法

IUF--inverse user frequency，用户活跃度对数的倒数，活跃用户对物品相似度的贡献应该小于不活跃的用户。用IUF参数修正物品相似度计算公式

![](../.gitbook/assets/image%20%2841%29.png)

此公式只是做了一种软性的惩罚，对于过于活跃的用户，为避免相似度矩阵过于稠密，在实际计算中直接忽略他的兴趣列表，不将其纳入到相似度计算的数据集中。

![&#x8986;&#x76D6;&#x7387;&#x8981;&#x597D;&#x4E00;&#x4E9B;](../.gitbook/assets/image%20%2854%29.png)

#### 物品相似度的归一性：

如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率、coverage和多样性。此时 $$w'_{ij}=\frac{w_{ij}}{max_jw_{ij}}$$ 。热门的类其类内物品相似度比较大，如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的，coverage比较低

![&#x5F52;&#x4E00;&#x5316;&#x7684;&#x5404;&#x9879;&#x6027;&#x80FD;&#x90FD;&#x6709;&#x6240;&#x63D0;&#x9AD8;](../.gitbook/assets/image%20%2843%29.png)

### 哈利波特问题

因为《哈利波特》太热门，购买任何一本书的人似乎都会购买《哈利波特》，原因在上面已经分析过。解决办法有几种：

* 在分母上加大对热门物品的惩罚，如$$w_{ij}=\frac{|N(i)\bigcap{N(j)}|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}$$其中 $$\alpha\in[0.5,1]$$ ， $$\alpha=0.5$$ 就是标准的ItemCF，提高alpha可以惩罚热门的j，coverage就越高，流行度会降低。但此方案会牺牲precision和recall的性能。
* 两个不同领域的最热门物品之间往往具有比较高的相似度，每个用户一般都会在不同的领域喜欢一种物品。此时仅仅依靠用户行为数据不能解决问题，需要引入物品的内容数据，如对不同领域的物品降低权重等。



## UserCF和ItemCF的比较

|  | UserCF | ItemCF |
| :--- | :--- | :--- |
| 着重 | 反映和用户兴趣相似的小群体的热点，更社会化 | 维系用户的历史兴趣，更个性化反映用户自己的兴趣传承 |
| 性能 | 维护用户矩阵，适合用户较少的场合 | 维护物品数明显小于用户数的场合 |
| 领域 | 时效性强，用户个性化兴趣不太明显 | 长尾物品丰富，用户个性化需求强烈 |
| 适合 | 热门新闻推荐 | 图书、电子商务和电影推荐 |

虽然基本算法中ItemCF比UserCF的离线性能好一些，但经过优化后，两者可以达到近似的离线性能。

